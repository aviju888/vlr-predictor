#!/usr/bin/env python3
"""
Truly Fix Data Leakage - Use Only Historical Features
====================================================

This script creates a model that uses ONLY historical win/loss data,
with NO outcome-based features (ACS, K/D, etc.).
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
import joblib
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def create_historical_features_only(df, cutoff_date):
    """
    Create features using ONLY historical win/loss records.
    NO ACS, K/D, or any outcome-based features.
    """
    print(f"Creating PURELY historical features with cutoff: {cutoff_date}")
    
    # Filter to only historical data
    historical_df = df[df['date'] <= cutoff_date].copy()
    
    features = []
    
    for _, row in df.iterrows():
        teamA, teamB, map_name = row['teamA'], row['teamB'], row['map_name']
        match_date = row['date']
        
        # Only use data BEFORE this match
        teamA_history = historical_df[
            ((historical_df['teamA'] == teamA) | (historical_df['teamB'] == teamA)) &
            (historical_df['date'] < match_date)
        ]
        teamB_history = historical_df[
            ((historical_df['teamA'] == teamB) | (historical_df['teamB'] == teamB)) &
            (historical_df['date'] < match_date)
        ]
        
        # Calculate PURELY historical features (no outcome data)
        
        # 1. Overall winrate difference
        teamA_wins = len(teamA_history[teamA_history['winner'] == teamA])
        teamA_total = len(teamA_history)
        teamA_winrate = teamA_wins / max(teamA_total, 1)
        
        teamB_wins = len(teamB_history[teamB_history['winner'] == teamB])
        teamB_total = len(teamB_history)
        teamB_winrate = teamB_wins / max(teamB_total, 1)
        
        # 2. Map-specific winrate difference
        teamA_map_matches = teamA_history[teamA_history['map_name'] == map_name]
        teamB_map_matches = teamB_history[teamB_history['map_name'] == map_name]
        
        teamA_map_wins = len(teamA_map_matches[teamA_map_matches['winner'] == teamA])
        teamA_map_total = len(teamA_map_matches)
        teamA_map_winrate = teamA_map_wins / max(teamA_map_total, 1)
        
        teamB_map_wins = len(teamB_map_matches[teamB_map_matches['winner'] == teamB])
        teamB_map_total = len(teamB_map_matches)
        teamB_map_winrate = teamB_map_wins / max(teamB_map_total, 1)
        
        # 3. Head-to-head record
        h2h_matches = historical_df[
            ((historical_df['teamA'] == teamA) & (historical_df['teamB'] == teamB)) |
            ((historical_df['teamA'] == teamB) & (historical_df['teamB'] == teamA))
        ]
        h2h_matches = h2h_matches[h2h_matches['date'] < match_date]
        
        teamA_h2h_wins = len(h2h_matches[h2h_matches['winner'] == teamA])
        teamB_h2h_wins = len(h2h_matches[h2h_matches['winner'] == teamB])
        h2h_total = len(h2h_matches)
        
        if h2h_total > 0:
            h2h_advantage = (teamA_h2h_wins - teamB_h2h_wins) / h2h_total
        else:
            h2h_advantage = 0
        
        # 4. Recent form (last 3 matches)
        teamA_recent = teamA_history.tail(3)
        teamB_recent = teamB_history.tail(3)
        
        teamA_recent_wins = len(teamA_recent[teamA_recent['winner'] == teamA])
        teamA_recent_winrate = teamA_recent_wins / max(len(teamA_recent), 1)
        
        teamB_recent_wins = len(teamB_recent[teamB_recent['winner'] == teamB])
        teamB_recent_winrate = teamB_recent_wins / max(len(teamB_recent), 1)
        
        # 5. Experience difference (total matches played)
        experience_diff = teamA_total - teamB_total
        
        # 6. Days since last match (rest factor)
        if len(teamA_history) > 0:
            teamA_last_match = teamA_history['date'].max()
            teamA_days_rest = (match_date - teamA_last_match).days
        else:
            teamA_days_rest = 30  # Default if no history
        
        if len(teamB_history) > 0:
            teamB_last_match = teamB_history['date'].max()
            teamB_days_rest = (match_date - teamB_last_match).days
        else:
            teamB_days_rest = 30  # Default if no history
        
        rest_advantage = teamA_days_rest - teamB_days_rest
        
        # Feature vector (ONLY historical win/loss data)
        feature_vector = [
            teamA_winrate - teamB_winrate,  # Overall winrate difference
            teamA_map_winrate - teamB_map_winrate,  # Map-specific winrate difference
            h2h_advantage,  # Head-to-head advantage
            teamA_recent_winrate - teamB_recent_winrate,  # Recent form difference
            experience_diff,  # Experience difference
            rest_advantage,  # Rest advantage
        ]
        
        features.append(feature_vector)
    
    return np.array(features)

def main():
    print("üîß TRULY FIXING DATA LEAKAGE - Historical Features Only")
    print("=" * 60)
    
    # Load data
    data_path = Path("data/map_matches_365d.csv")
    if not data_path.exists():
        print("‚ùå No data found. Please run data collection first.")
        return
    
    print("üìä Loading data...")
    df = pd.read_csv(data_path)
    df['date'] = pd.to_datetime(df['date'])
    
    print(f"‚úÖ Loaded {len(df)} matches from {df['date'].min()} to {df['date'].max()}")
    
    # Sort by date
    df = df.sort_values('date').reset_index(drop=True)
    
    # Create temporal split
    split_date = df['date'].quantile(0.8)
    train_df = df[df['date'] <= split_date].copy()
    test_df = df[df['date'] > split_date].copy()
    
    print(f"üìÖ Training: {train_df['date'].min()} to {train_df['date'].max()} ({len(train_df)} matches)")
    print(f"üìÖ Testing: {test_df['date'].min()} to {test_df['date'].max()} ({len(test_df)} matches)")
    
    # Create features with NO outcome-based data
    print("\nüî® Creating PURELY historical features...")
    X_train = create_historical_features_only(train_df, split_date)
    X_test = create_historical_features_only(test_df, split_date)
    
    # Prepare targets
    y_train = (train_df['winner'] == train_df['teamA']).astype(int)
    y_test = (test_df['winner'] == test_df['teamA']).astype(int)
    
    print(f"‚úÖ Feature matrix shapes: Train {X_train.shape}, Test {X_test.shape}")
    
    # Train model
    print("\nü§ñ Training model...")
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    
    pipeline.fit(X_train, y_train)
    
    # Make predictions
    y_pred = pipeline.predict(X_test)
    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nüìà RESULTS (Purely Historical Features):")
    print(f"   Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)")
    print(f"   Expected: 0.55-0.70 (55-70%)")
    
    if accuracy > 0.80:
        print("   ‚ö†Ô∏è  Still too high - possible remaining leakage")
    elif accuracy < 0.50:
        print("   ‚ö†Ô∏è  Too low - model may be underfitting")
    else:
        print("   ‚úÖ Realistic accuracy range!")
    
    # Detailed analysis
    print(f"\nüìä Detailed Analysis:")
    print(f"   Correct predictions: {sum(y_pred == y_test)}/{len(y_test)}")
    print(f"   Average confidence: {np.mean(np.maximum(y_pred_proba, 1-y_pred_proba)):.3f}")
    
    # Show some example predictions
    print(f"\nüîç Example Predictions:")
    for i in range(min(5, len(test_df))):
        row = test_df.iloc[i]
        prob = y_pred_proba[i]
        predicted = "Team A" if prob > 0.5 else "Team B"
        actual = "Team A" if y_test.iloc[i] else "Team B"
        correct = "‚úÖ" if predicted == actual else "‚ùå"
        
        print(f"   {row['teamA']} vs {row['teamB']} on {row['map_name']}")
        print(f"     Predicted: {predicted} ({prob:.3f}) | Actual: {actual} {correct}")
    
    # Save the model
    artifacts_dir = Path("artifacts")
    artifacts_dir.mkdir(exist_ok=True)
    
    model_path = artifacts_dir / "historical_only_model.joblib"
    joblib.dump(pipeline, model_path)
    
    print(f"\nüíæ Saved historical-only model to {model_path}")
    
    # Create report
    report_path = Path("reports/report-3-historical-only.md")
    report_path.parent.mkdir(exist_ok=True)
    
    with open(report_path, 'w') as f:
        f.write(f"""# Report 3: Historical Features Only

## Summary
Created a model using ONLY historical win/loss data, with NO outcome-based features.

## Key Changes
1. **No ACS/K/D**: Removed all outcome-based features
2. **Historical Only**: Features calculated only from past matches
3. **Win/Loss Data**: Only used match results, not performance metrics
4. **Temporal Split**: Proper train/test split by date

## Features Used
1. Overall winrate difference
2. Map-specific winrate difference  
3. Head-to-head record
4. Recent form (last 3 matches)
5. Experience difference (total matches)
6. Rest advantage (days since last match)

## Results
- **Accuracy**: {accuracy:.3f} ({accuracy*100:.1f}%)
- **Training Period**: {train_df['date'].min()} to {train_df['date'].max()}
- **Testing Period**: {test_df['date'].min()} to {test_df['date'].max()}
- **Training Matches**: {len(train_df)}
- **Testing Matches**: {len(test_df)}

## Validation
- ‚úÖ No outcome-based features
- ‚úÖ Only historical win/loss data
- ‚úÖ Proper temporal constraints
- ‚úÖ Model saved as `historical_only_model.joblib`

## Next Steps
1. Test on real VCT data
2. Add more sophisticated features
3. Implement proper calibration
""")
    
    print(f"üìù Created report: {report_path}")
    print("\nüéâ Data leakage truly fixed! Model uses only historical data.")

if __name__ == "__main__":
    main()
